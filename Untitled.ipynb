{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy\n",
    "import extract_features as exf\n",
    "import pandas as pd\n",
    "########\n",
    "\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "import urlparse\n",
    "import sekitei_segments\n",
    "import extract_featur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run test: lenta\n",
      "Run test: wikipedia\n",
      "Run test: zr\n",
      "=== Test summary ===\n",
      "lenta t: 19.6519999504  fetched rate: 0.3147 qlink rate:0.247333333333 : fail due execution time\n",
      "wikipedia t: 12.0530002117  fetched rate: 1.0 qlink rate:0.473333333333\n",
      "zr t: 13.757999897  fetched rate: 1.0 qlink rate:0.486\n",
      "\n",
      "average fetched rate: 0.666666666667 qlink rate: 0.319777777778\n",
      "\n",
      "F1 - score: 0.432229481114\n",
      "\n",
      "YOUR RESULT SCORE: 0\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "sekitei_segments = reload(sekitei_segments)\n",
    "exf = reload(extract_features)\n",
    "\n",
    "def extract_names(f):\n",
    "    m = re.search(r'urls\\.(\\w+)\\.(\\w+)', f);\n",
    "    if m is not None:\n",
    "        return ( m.group(1), m.group(2), f) ;\n",
    "def read_feas(file_name):\n",
    "    result = {};\n",
    "    with open(file_name) as f:\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip();\n",
    "            p = line.split('\\t');\n",
    "            if len(p) >1: result[p[0]] = p[1];\n",
    "    return result            \n",
    "                \n",
    "def compare_results(result, pattern):\n",
    "    equals =0.\n",
    "    for p in pattern.keys():\n",
    "         if p in result:\n",
    "            equals += 1.\n",
    "    return equals/ len(pattern);\n",
    "\n",
    "def shufle_urls_from_file(FILE_NAME):\n",
    "    urls = [];\n",
    "    with open(FILE_NAME ) as i_file:\n",
    "         for line in i_file:\n",
    "            line = line.strip();\n",
    "            urls.append(line);\n",
    "    random.shuffle(urls)\n",
    "    return urls;\n",
    "\n",
    "#\n",
    "# paths\n",
    "#\n",
    "INPUT_PATH='./data/'\n",
    "CHECK_PATH='./check/'\n",
    "\n",
    "if os.path.exists(INPUT_PATH) != True:\n",
    "    print >> sys.stderr, \"Missing input path \" + INPUT_PATHT;\n",
    "    sys.exit(1);\n",
    "    \n",
    "if os.path.exists(CHECK_PATH) != True:\n",
    "    print >> sys.stderr, \"Missing check path \" + CHECK_PATH;\n",
    "    sys.exit(1);\n",
    "    \n",
    "files = os.listdir(INPUT_PATH);\n",
    "files = sorted(files)\n",
    "names = map(extract_names, files)\n",
    "\n",
    "#\n",
    "# defines \n",
    "#\n",
    "count = len(names) / 2\n",
    "curl_for_segments = 500;\n",
    "MAX_QUOTA = 10000\n",
    "result = [];\n",
    "MAX_TIME = 15.;\n",
    "MIN_RATE = 0.7\n",
    "\n",
    "#\n",
    "# check loop\n",
    "#\n",
    "for i in range(0, count):\n",
    "    name = names[i*2][0]\n",
    "    print \"Run test: \" + names[i*2][0]\n",
    "    \n",
    "    \n",
    "    f1 = INPUT_PATH + names[i*2][2]\n",
    "    qlink_urls = shufle_urls_from_file(f1);    \n",
    "    f2 = INPUT_PATH + names[i*2+1][2]\n",
    "    unk_urls = shufle_urls_from_file(f2);\n",
    "            \n",
    "    t1 = time.time() \n",
    "    # define segments here\n",
    "    sekitei_segments.define_segments(qlink_urls[:curl_for_segments], \n",
    "                                     unk_urls[:curl_for_segments],\n",
    "                                     MAX_QUOTA);\n",
    "    qlink_urls = [(1, url) for url in qlink_urls[curl_for_segments:]];\n",
    "    unk_urls = [(0, url) for url in unk_urls[curl_for_segments:] ];\n",
    "    \n",
    "    urls_mix = []\n",
    "    urls_mix.extend(qlink_urls);\n",
    "    urls_mix.extend(unk_urls);\n",
    "    random.shuffle(urls_mix)\n",
    "    \n",
    "    urls_fetched = 0;\n",
    "    qlinks_fetched = 0    \n",
    "    qlinks_count = len(qlink_urls);\n",
    "    \n",
    "    for url in urls_mix:\n",
    "        if sekitei_segments.fetch_url(url[1]) :\n",
    "            urls_fetched +=1;\n",
    "            qlinks_fetched += url[0];\n",
    "        if urls_fetched >= MAX_QUOTA:\n",
    "            break;\n",
    "    t2 = time.time() \n",
    "    result.append((name, (t2-t1), float(urls_fetched), float(qlinks_fetched), float(qlinks_count) ) );\n",
    "\n",
    "print \"=== Test summary ===\";\n",
    "out= ''\n",
    "avg_qlink_rate = 0\n",
    "avg_fetched = 0;\n",
    "for r in result:    \n",
    "    out = r[0] + \" t: \" + str(r[1]) + \"  fetched rate: \" + str(r[2]/MAX_QUOTA)                 + \" qlink rate:\" + str(r[3] / r[4] )\n",
    "        \n",
    "    if r[1] > MAX_TIME:\n",
    "        out += \" : fail due execution time\" \n",
    "    else :\n",
    "        avg_qlink_rate += r[3] / r[4] \n",
    "        avg_fetched += r[2]/MAX_QUOTA;\n",
    "    \n",
    "    print out;\n",
    "    \n",
    "avg_qlink_rate /= len(result);\n",
    "avg_fetched /= len(result);\n",
    "print \"\\naverage fetched rate: \" + str(avg_fetched) + \" qlink rate: \" + str(avg_qlink_rate);\n",
    "f1 =  (2 * avg_qlink_rate * avg_fetched) / (avg_qlink_rate + avg_fetched )\n",
    "print \"\\nF1 - score: \" + str(f1);\n",
    "print \"\"\n",
    "\n",
    "if f1 < MIN_RATE:\n",
    "    print \"YOUR RESULT SCORE: 0\";\n",
    "else:    \n",
    "    if f1 > 0.9:\n",
    "        print \"YOUR RESULT SCORE: 5\";\n",
    "    else:\n",
    "        if f1 > 0.8:\n",
    "            print \"YOUR RESULT SCORE: 4\";\n",
    "        else:\n",
    "            if f1 > 0.7:\n",
    "                print \"YOUR RESULT SCORE: 3\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.append(d1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(d1, columns=df.columns.intersection(d1), index = [1]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"lib\" in df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
